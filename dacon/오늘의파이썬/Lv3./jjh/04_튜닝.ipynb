{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train[['fixed acidity']])\n",
    "train['Scaled fixed acidity'] = scaler.transform(train[['fixed acidity']])\n",
    "test['Scaled fixed acidity'] = scaler.transform(test[['fixed acidity']])\n",
    "\n",
    "# 인코딩\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(train[['type']])\n",
    "onehot = encoder.transform(train[['type']])\n",
    "onehot = onehot.toarray()\n",
    "onehot = pd.DataFrame(onehot)\n",
    "onehot.columns = encoder.get_feature_names()\n",
    "train = pd.concat([train, onehot], axis=1)\n",
    "train = train.drop(columns = ['type'])\n",
    "\n",
    "onehot = encoder.transform(test[['type']])\n",
    "onehot = onehot.toarray()\n",
    "onehot = pd.DataFrame(onehot)\n",
    "onehot.columns = encoder.get_feature_names()\n",
    "test = pd.concat([test, onehot], axis=1)\n",
    "test = test.drop(columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터와 목표 변수 구분\n",
    "x = train.drop(columns=['index', 'quality'])\n",
    "y = train['quality']\n",
    "\n",
    "# 랜덤포레스트 하이퍼파라미터 범위 지정\n",
    "rf_parameter_bounds = {\n",
    "    'max_depth': (1, 3), # 트리 깊이\n",
    "    'n_estimators': (30, 100),\n",
    "}\n",
    "\n",
    "# 함수 생성\n",
    "def rf_bo(max_depth, n_estimators):\n",
    "    rf_params={\n",
    "        'max_depth': int(round(max_depth)),\n",
    "        'n_estimators': int(round(n_estimators)),\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(**rf_params)\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "    rf.fit(x_train, y_train)\n",
    "    score = accuracy_score(y_valid, rf.predict(x_valid))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Optimization 객체 생성\n",
    "Bo_rf = BayesianOptimization(f=rf_bo, pbounds=rf_parameter_bounds, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | n_esti... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.53    \u001b[0m | \u001b[0m 2.098   \u001b[0m | \u001b[0m 80.06   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.5336  \u001b[0m | \u001b[95m 2.206   \u001b[0m | \u001b[95m 68.14   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5218  \u001b[0m | \u001b[0m 1.847   \u001b[0m | \u001b[0m 75.21   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5264  \u001b[0m | \u001b[0m 1.875   \u001b[0m | \u001b[0m 92.42   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5327  \u001b[0m | \u001b[0m 2.927   \u001b[0m | \u001b[0m 56.84   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.4655  \u001b[0m | \u001b[0m 1.018   \u001b[0m | \u001b[0m 48.01   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.5382  \u001b[0m | \u001b[95m 2.596   \u001b[0m | \u001b[95m 62.47   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5255  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 30.0    \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.5491  \u001b[0m | \u001b[95m 3.0     \u001b[0m | \u001b[95m 100.0   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.4391  \u001b[0m | \u001b[0m 1.009   \u001b[0m | \u001b[0m 98.09   \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "# Bayesian Optimization 실행\n",
    "Bo_rf.maximize(init_points=5, n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "max_params = Bo_rf.max['params']\n",
    "\n",
    "max_params['max_depth'] = int(max_params['max_depth'])\n",
    "max_params['n_estimators'] = int(max_params['n_estimators'])\n",
    "print(max_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Optimization 결과 저장\n",
    "Bo_tuend_rf = RandomForestClassifier(**max_params)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
