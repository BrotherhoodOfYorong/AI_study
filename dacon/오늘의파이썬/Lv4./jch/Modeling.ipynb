{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c336c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 실습\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "train.drop('index', axis = 1, inplace = True)\n",
    "test.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe99b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.042</td>\n",
       "      <td>9.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.99432</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.2</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.067</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>21.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.99176</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.52</td>\n",
       "      <td>10.9</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.046</td>\n",
       "      <td>29.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.99390</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.26</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.059</td>\n",
       "      <td>32.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.9</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5492</th>\n",
       "      <td>5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.029</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.99320</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.1</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5493</th>\n",
       "      <td>6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.034</td>\n",
       "      <td>26.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99074</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.51</td>\n",
       "      <td>11.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5494</th>\n",
       "      <td>7</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.035</td>\n",
       "      <td>31.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99096</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.72</td>\n",
       "      <td>11.3</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.042</td>\n",
       "      <td>18.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99195</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>10.5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.049</td>\n",
       "      <td>7.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.99297</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      quality  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0           5            5.6             0.695         0.06             6.8   \n",
       "1           5            8.8             0.610         0.14             2.4   \n",
       "2           5            7.9             0.210         0.39             2.0   \n",
       "3           6            7.0             0.210         0.31             6.0   \n",
       "4           6            7.8             0.400         0.26             9.5   \n",
       "...       ...            ...               ...          ...             ...   \n",
       "5492        5            7.7             0.150         0.29             1.3   \n",
       "5493        6            6.3             0.180         0.36             1.2   \n",
       "5494        7            7.8             0.150         0.34             1.1   \n",
       "5495        5            6.6             0.410         0.31             1.6   \n",
       "5496        6            7.0             0.350         0.17             1.1   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0         0.042                  9.0                  84.0  0.99432  3.44   \n",
       "1         0.067                 10.0                  42.0  0.99690  3.19   \n",
       "2         0.057                 21.0                 138.0  0.99176  3.05   \n",
       "3         0.046                 29.0                 108.0  0.99390  3.26   \n",
       "4         0.059                 32.0                 178.0  0.99550  3.04   \n",
       "...         ...                  ...                   ...      ...   ...   \n",
       "5492      0.029                 10.0                  64.0  0.99320  3.35   \n",
       "5493      0.034                 26.0                 111.0  0.99074  3.16   \n",
       "5494      0.035                 31.0                  93.0  0.99096  3.07   \n",
       "5495      0.042                 18.0                 101.0  0.99195  3.13   \n",
       "5496      0.049                  7.0                 119.0  0.99297  3.13   \n",
       "\n",
       "      sulphates  alcohol   type  \n",
       "0          0.44     10.2  white  \n",
       "1          0.59      9.5    red  \n",
       "2          0.52     10.9  white  \n",
       "3          0.50     10.8  white  \n",
       "4          0.43     10.9  white  \n",
       "...         ...      ...    ...  \n",
       "5492       0.39     10.1  white  \n",
       "5493       0.51     11.0  white  \n",
       "5494       0.72     11.3  white  \n",
       "5495       0.41     10.5  white  \n",
       "5496       0.36      9.7  white  \n",
       "\n",
       "[5497 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02290aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one = pd.get_dummies(train)\n",
    "test_one = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f97ef3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc77b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\freshman\\Desktop\\AI\\ai\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:20:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_one.drop('quality', axis = 1)\n",
    "y = train_one['quality']\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6ea04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3fd8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['quality'] = pred\n",
    "submission.to_csv('xgb_pred.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0bfc31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 실습\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "train.drop('index', axis = 1, inplace = True)\n",
    "test.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85911419",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one = pd.get_dummies(train)\n",
    "test_one = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a015c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5163a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_one.drop('quality', axis = 1)\n",
    "y = train_one['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c59ea08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8be95053",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04b74dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['quality'] = pred\n",
    "submission.to_csv('lgbm_pred.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9750294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified k-fold로 교차검증 후, LightGBM을 이용해 와인 품질 분류\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab978ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "train.drop('index', axis = 1, inplace = True)\n",
    "test.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "X = train_one.drop('quality', axis = 1)\n",
    "y = train_one['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11fb4b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 모델 정확도 : 0.6609090909090909\n",
      "2번째 모델 정확도 : 0.6581818181818182\n",
      "3번째 모델 정확도 : 0.6606005459508644\n",
      "4번째 모델 정확도 : 0.632393084622384\n",
      "5번째 모델 정확도 : 0.6469517743403094\n",
      "모델 정확도 평균 : 0.6518072628008933\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "acc = 0\n",
    "for train_idx, valid_idx in skf.split(X, y):\n",
    "    train_data = train_one.iloc[train_idx]\n",
    "    valid_data = train_one.iloc[valid_idx]\n",
    "    \n",
    "    model = LGBMClassifier()\n",
    "    \n",
    "    train_X = train_data.drop('quality', axis = 1)\n",
    "    train_y = train_data['quality']\n",
    "    \n",
    "    model.fit(train_X, train_y)\n",
    "    \n",
    "    valid_X = valid_data.drop('quality', axis = 1)\n",
    "    valid_y = valid_data['quality']\n",
    "    \n",
    "    pred = model.predict(valid_X)\n",
    "    \n",
    "    print(f\"{cnt}번째 모델 정확도 :\", accuracy_score(pred, valid_y))\n",
    "    acc += accuracy_score(pred, valid_y)\n",
    "    cnt += 1\n",
    "    \n",
    "print('모델 정확도 평균 :', acc / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d39fc9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\freshman\\Desktop\\AI\\ai\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:46:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# Voting Classifier 실습\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "train.drop('index', axis = 1, inplace = True)\n",
    "test.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "X = train_one.drop('quality', axis = 1)\n",
    "y = train_one['quality']\n",
    "\n",
    "LGBM = LGBMClassifier()\n",
    "XGB = XGBClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "VC = VotingClassifier(estimators = [('rf', RF), ('xgb', XGB), ('lgbm', LGBM)], voting = 'soft')\n",
    "\n",
    "X = train_one.drop('quality', axis = 1)\n",
    "y = train_one['quality']\n",
    "\n",
    "VC.fit(X, y)\n",
    "\n",
    "pred = VC.predict(test_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a0aed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 6, 5, 6, 6, 6, 6, 6, 7, 6, 6, 7, 6, 6, 5, 6, 6, 6, 6, 6, 6,\n",
       "       5, 7, 6, 5, 5, 5, 5, 5, 7, 6, 5, 6, 5, 6, 5, 5, 6, 6, 6, 5, 6, 6,\n",
       "       6, 7, 5, 6, 4, 6, 5, 5, 6, 4, 5, 6, 6, 5, 5, 6, 5, 6, 6, 4, 6, 6,\n",
       "       5, 5, 6, 5, 5, 5, 5, 6, 6, 5, 6, 6, 6, 7, 6, 6, 5, 5, 6, 5, 5, 5,\n",
       "       6, 7, 6, 6, 6, 6, 6, 7, 6, 6, 6, 7, 5, 6, 6, 5, 5, 6, 6, 6, 7, 5,\n",
       "       6, 6, 6, 5, 5, 6, 6, 7, 7, 6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 7, 5, 5,\n",
       "       6, 5, 5, 6, 6, 7, 5, 5, 5, 6, 5, 5, 5, 5, 7, 6, 7, 6, 5, 8, 6, 5,\n",
       "       6, 5, 5, 5, 6, 5, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 5, 6, 5, 6, 6,\n",
       "       6, 5, 6, 6, 6, 6, 7, 7, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 7, 5,\n",
       "       5, 5, 6, 5, 6, 5, 5, 5, 6, 6, 6, 6, 7, 5, 5, 6, 6, 6, 6, 6, 6, 7,\n",
       "       6, 5, 6, 6, 7, 6, 6, 5, 6, 5, 6, 7, 7, 6, 6, 6, 6, 6, 6, 7, 6, 6,\n",
       "       6, 6, 7, 6, 6, 7, 6, 6, 5, 6, 7, 7, 6, 6, 6, 7, 7, 6, 7, 5, 5, 7,\n",
       "       5, 5, 6, 5, 6, 6, 6, 5, 5, 5, 6, 5, 7, 7, 5, 6, 6, 6, 6, 6, 7, 7,\n",
       "       6, 6, 6, 6, 5, 5, 5, 6, 5, 7, 8, 5, 5, 7, 7, 6, 5, 5, 6, 7, 5, 7,\n",
       "       5, 5, 6, 5, 6, 5, 6, 6, 5, 5, 6, 6, 5, 5, 6, 5, 4, 5, 5, 6, 6, 6,\n",
       "       5, 7, 7, 5, 5, 6, 5, 6, 6, 6, 5, 6, 7, 6, 5, 6, 5, 6, 5, 6, 5, 6,\n",
       "       5, 6, 6, 5, 6, 6, 5, 6, 5, 6, 6, 7, 7, 6, 5, 5, 7, 6, 6, 6, 5, 5,\n",
       "       6, 5, 5, 6, 6, 6, 7, 6, 7, 6, 5, 6, 6, 5, 6, 6, 7, 5, 7, 6, 5, 6,\n",
       "       5, 7, 7, 5, 7, 6, 6, 6, 7, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6,\n",
       "       5, 6, 7, 6, 5, 5, 6, 6, 6, 6, 5, 6, 7, 5, 5, 6, 6, 4, 6, 5, 5, 5,\n",
       "       5, 7, 6, 5, 6, 6, 5, 5, 5, 6, 6, 7, 5, 6, 6, 6, 7, 5, 6, 5, 5, 6,\n",
       "       5, 5, 5, 6, 6, 6, 6, 5, 5, 5, 5, 6, 5, 6, 6, 8, 7, 6, 6, 7, 5, 5,\n",
       "       8, 5, 5, 6, 5, 6, 7, 6, 5, 7, 5, 6, 6, 5, 6, 6, 6, 6, 6, 7, 6, 5,\n",
       "       6, 7, 6, 7, 5, 5, 6, 6, 6, 5, 5, 7, 6, 5, 5, 5, 5, 7, 6, 5, 7, 6,\n",
       "       6, 6, 5, 5, 6, 5, 6, 6, 6, 6, 4, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6,\n",
       "       6, 6, 6, 6, 5, 6, 5, 5, 5, 6, 5, 5, 6, 6, 7, 6, 6, 7, 6, 5, 6, 5,\n",
       "       5, 7, 6, 5, 6, 5, 5, 5, 6, 6, 5, 5, 6, 7, 7, 7, 5, 7, 6, 5, 7, 6,\n",
       "       5, 5, 5, 7, 6, 6, 6, 6, 6, 7, 5, 6, 5, 5, 7, 6, 8, 5, 6, 6, 6, 6,\n",
       "       5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 6, 5, 6, 6, 5, 5, 7, 5, 6,\n",
       "       8, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 7, 6, 5, 6, 6, 6, 5,\n",
       "       7, 5, 6, 5, 7, 6, 6, 5, 6, 5, 6, 5, 6, 7, 5, 5, 6, 6, 7, 7, 6, 6,\n",
       "       7, 5, 7, 8, 6, 6, 5, 6, 7, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 5, 5,\n",
       "       5, 6, 5, 6, 5, 5, 6, 5, 6, 5, 7, 6, 5, 6, 6, 6, 5, 6, 8, 5, 5, 6,\n",
       "       6, 4, 7, 6, 5, 7, 5, 5, 7, 6, 5, 7, 6, 5, 6, 5, 6, 5, 6, 6, 7, 6,\n",
       "       5, 5, 6, 5, 6, 6, 6, 7, 5, 7, 6, 6, 5, 5, 6, 7, 6, 6, 5, 6, 5, 6,\n",
       "       5, 6, 6, 5, 6, 6, 6, 5, 6, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6,\n",
       "       6, 6, 7, 6, 6, 5, 6, 5, 5, 5, 6, 6, 5, 6, 5, 7, 7, 6, 6, 6, 5, 7,\n",
       "       7, 5, 6, 6, 6, 5, 6, 5, 5, 5, 8, 6, 6, 5, 8, 6, 6, 6, 6, 5, 7, 6,\n",
       "       5, 7, 5, 5, 5, 6, 6, 5, 6, 6, 7, 7, 7, 6, 5, 7, 5, 6, 5, 5, 6, 6,\n",
       "       5, 6, 5, 6, 5, 5, 6, 6, 5, 7, 5, 6, 7, 7, 6, 6, 5, 5, 6, 5, 6, 6,\n",
       "       5, 6, 5, 5, 5, 7, 5, 6, 7, 5, 5, 6, 6, 5, 5, 5, 6, 6, 6, 7, 6, 6,\n",
       "       5, 7, 5, 6, 5, 7, 5, 6, 6, 6, 5, 6, 6, 8, 7, 6, 5, 5, 6, 6, 6, 6,\n",
       "       6, 5, 6, 5, 6, 5, 5, 5, 5, 6, 5, 6, 5, 6, 4, 6, 5, 6, 6, 5, 8, 6,\n",
       "       6, 5, 6, 6, 6, 8, 6, 6, 6, 6, 6, 7, 6, 6, 5, 5, 5, 5, 6, 5, 5, 5,\n",
       "       5, 7, 6, 6, 7, 7, 6, 5, 7, 6, 6, 6, 6, 5, 6, 5, 5, 6, 6, 5, 5, 5,\n",
       "       6, 6, 6, 6, 6, 6, 6, 5, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9544401",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['quality'] = pred\n",
    "submission.to_csv('VC.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943299a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
